{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Counter\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = loadmat(\"../data/mnist_all.mat\")\n",
    "\n",
    "    # print(data.keys())\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(10):\n",
    "        temp_df = pd.DataFrame(data[\"train\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        train_data = train_data.append(temp_df)\n",
    "        temp_df = pd.DataFrame(data[\"test\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        test_data = test_data.append(temp_df)\n",
    "\n",
    "    train_data = shuffle(train_data)\n",
    "    test_data = shuffle(test_data)\n",
    "\n",
    "    train_labels = np.array(train_data['label'])\n",
    "    test_labels = np.array(test_data['label'])\n",
    "\n",
    "    train_data = train_data.drop('label', axis=1)\n",
    "    test_data = test_data.drop('label', axis=1)\n",
    "    \n",
    "    train_data = np.array(train_data) / 255\n",
    "    test_data = np.array(test_data) / 255\n",
    "    \n",
    "    pca = PCA(0.95)\n",
    "    pca.fit(train_data)\n",
    "    train_data = pca.transform(train_data)\n",
    "    test_data = pca.transform(test_data)\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意，经过PCA降维后，认为所有的特征都是连续值\n",
    "X = np.concatenate((X_train, X_valid), axis=0)\n",
    "y = np.concatenate((y_train, y_valid), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 154) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "sklearn_gbdt = GradientBoostingClassifier(n_estimators=2, max_depth=3)\n",
    "sklearn_gbdt.fit(X[:100], y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sklearn = sklearn_gbdt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn gbdt test acc: 0.3651\n"
     ]
    }
   ],
   "source": [
    "print('sklearn gbdt test acc: {}'.format((sum(predict_sklearn == np.array(y_test)))/len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree:\n",
    "    def __init__(self, min_samples_leaf, K, max_depth=3):\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.K = K\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        depth = 0\n",
    "        self.tree = self.build_tree(x, y, depth)\n",
    "        \n",
    "    \n",
    "    def build_tree(self, x, y, depth):\n",
    "        \n",
    "        best_feature_index, threshold, c1, c2 = self.choose_best_feature_to_split(x, y)\n",
    "        \n",
    "        tree = {}\n",
    "        x1, y1, x2, y2 = self.split_data(x, y, best_feature_index, threshold)\n",
    "        \n",
    "        \n",
    "        # 构造树的终止条件\n",
    "        if len(x1) < self.min_samples_leaf or depth >= self.max_depth:\n",
    "            # 这里需要符合gbdt的公式\n",
    "            sum1 = sum(y1)\n",
    "            sum2 = sum([abs(_y)*(1-abs(_y)) for _y in y1])\n",
    "            \n",
    "            if sum1 == 0 or sum2 == 0:\n",
    "                v = 0\n",
    "            else:\n",
    "                v = ((self.K-1)/self.K)*(sum1/sum2)\n",
    "                \n",
    "            tree[(best_feature_index, threshold, '<=')] = v\n",
    "        else:\n",
    "            tree[(best_feature_index, threshold, '<=')] = self.build_tree(x1, y1, depth + 1)\n",
    "            \n",
    "        if len(x2) < self.min_samples_leaf or depth >= self.max_depth:\n",
    "            # 这里需要符合gbdt的公式\n",
    "            sum1 = sum(y2)\n",
    "            sum2 = sum([abs(_y)*(1-abs(_y)) for _y in y2])\n",
    "            \n",
    "            if sum1 == 0 or sum2 == 0:\n",
    "                v = 0\n",
    "            else:\n",
    "                v = ((self.K-1)/self.K)*(sum1/sum2)\n",
    "            \n",
    "            tree[(best_feature_index, threshold, '>')] = v\n",
    "        else:\n",
    "            tree[(best_feature_index, threshold, '>')] = self.build_tree(x2, y2, depth + 1)\n",
    "            \n",
    "        return tree\n",
    "    \n",
    "            \n",
    "    def split_data(self, x, y, best_feature_index, threshold):\n",
    "        \n",
    "        x1, x2, y1, y2 = [], [], [], []\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            if x[i][best_feature_index] <= threshold:\n",
    "                x1.append(x[i])\n",
    "                y1.append(y[i])\n",
    "            else:\n",
    "                x2.append(x[i])\n",
    "                y2.append(y[i])\n",
    "        \n",
    "        return np.array(x1), np.array(y1), np.array(x2), np.array(y2)\n",
    "    \n",
    "    \n",
    "    def calculate_mse(self, feature_index, x, y):\n",
    "        values = []\n",
    "        for i in range(len(x)):\n",
    "            values.append(x[i][feature_index])\n",
    "        \n",
    "        values = list(set(values))\n",
    "        \n",
    "        n1, n2 = 0, 0\n",
    "        y1, y2 = 0, 0\n",
    "        \n",
    "        best_mse = sys.maxsize\n",
    "        best_threshold = None\n",
    "        best_c1, best_c2 = None, None\n",
    "        \n",
    "        for value in values:\n",
    "            for i in range(len(x)):\n",
    "                if x[i][feature_index] <= value:\n",
    "                    n1 += 1\n",
    "                    y1 += y[i]\n",
    "                elif x[i][feature_index] > value:\n",
    "                    n2 += 1\n",
    "                    y2 += y[i]\n",
    "            \n",
    "            if n1 != 0:\n",
    "                c1 = y1/n1\n",
    "            else:\n",
    "                c1 = 0\n",
    "            \n",
    "            if n2 != 0:\n",
    "                c2 = y2/n2\n",
    "            else:\n",
    "                c2 = 0\n",
    "            \n",
    "            mse = 0\n",
    "            for i in range(len(x)):\n",
    "                if x[i][feature_index] <= value:\n",
    "                    mse += (c1 - y[i])*(c1 - y[i])\n",
    "                elif x[i][feature_index] > value:\n",
    "                    mse += (c2 - y[i])*(c2 - y[i])\n",
    "                    \n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_threshold = value\n",
    "                best_c1 = c1\n",
    "                best_c2 = c2\n",
    "        \n",
    "        # 不会发生\n",
    "        if best_threshold is None:\n",
    "            pass\n",
    "        \n",
    "        return best_mse, best_threshold, best_c1, best_c2\n",
    "    \n",
    "    \n",
    "    def choose_best_feature_to_split(self, x, y):\n",
    "        n_features = x.shape[1]\n",
    "        \n",
    "        best_feature_index = -1\n",
    "        best_mse = sys.maxsize\n",
    "        best_feature_threshold = None\n",
    "        best_c1 = None\n",
    "        best_c2 = None\n",
    "        \n",
    "        for feature_index in range(n_features):\n",
    "            mse, threshold, c1, c2 = self.calculate_mse(feature_index, x, y)\n",
    "            \n",
    "            if mse < best_mse:\n",
    "                best_feature_index = feature_index\n",
    "                best_mse = mse\n",
    "                best_feature_threshold = threshold\n",
    "                best_c1 = c1\n",
    "                best_c2 = c2\n",
    "        # 不会发生\n",
    "        if best_feature_index == -1:\n",
    "            pass\n",
    "        \n",
    "        return best_feature_index, best_feature_threshold, best_c1, best_c2\n",
    "    \n",
    "    \n",
    "    def predict_value(self, x):\n",
    "        tree = self.tree\n",
    "        \n",
    "        while type(tree).__name__ == 'dict':\n",
    "            \n",
    "            for key in tree.keys():\n",
    "                if key[2] == '<=':\n",
    "                    key1 = key\n",
    "                elif key[2] == '>':\n",
    "                    key2 = key\n",
    "                    \n",
    "            \n",
    "            feature_index = key1[0]\n",
    "            threshold = key1[1]\n",
    "            \n",
    "            if x[feature_index] <= threshold:\n",
    "                tree = tree[key1]\n",
    "            elif x[feature_index] > threshold:\n",
    "                tree = tree[key2]\n",
    "\n",
    "        \n",
    "        if type(tree).__name__ != 'dict':\n",
    "            return tree\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "         return np.array([self.predict_value(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDT:\n",
    "    def __init__(self, n_estimators, learning_rate, max_depth=3, min_samples_leaf=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        self.trees = {}\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        K = len(list(set(y)))\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "        y = [self.to_one_hot(K, _y) for _y in y]\n",
    "        \n",
    "        F = {}\n",
    "        p = {}\n",
    "        residual = {}\n",
    "        for i in range(len(x)):\n",
    "            F[i] = {}\n",
    "            p[i] = {}\n",
    "            residual[i] = {}\n",
    "            for k in range(K):\n",
    "                F[i][k] = 0.0\n",
    "                \n",
    "        for m in tqdm(range(self.n_estimators)):\n",
    "            \n",
    "            self.trees[m] = {}\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                denominator = sum([np.exp(F[i][_k]) for _k in range(K)])\n",
    "                for k in range(K):\n",
    "                    p[i][k] = np.exp(F[i][k])/denominator\n",
    "                    residual[i][k] = y[i][k] - p[i][k]\n",
    "                    \n",
    "            for k in range(K):\n",
    "                residuals = []\n",
    "                for i in range(len(x)):\n",
    "                    residuals.append(residual[i][k])\n",
    "                    \n",
    "                tree = RegressionTree(min_samples_leaf=self.min_samples_leaf, K=K)\n",
    "                \n",
    "                tree.fit(x, residuals)\n",
    "                \n",
    "                self.trees[m][k] = tree\n",
    "                    \n",
    "                # update F\n",
    "                for i in range(len(x)):\n",
    "                    F[i][k] += self.learning_rate * self.trees[m][k].predict_value(x[i])\n",
    "                    \n",
    "    \n",
    "    def predict_value(self, x):\n",
    "        p = [0]*self.K\n",
    "        for m in self.trees:\n",
    "            for k in range(self.K):\n",
    "                p[k] += self.learning_rate * self.trees[m][k].predict_value(x)\n",
    "        \n",
    "        return np.argmax(p)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_value(x) for x in X])\n",
    "    \n",
    "    \n",
    "    def to_one_hot(self, n_class, x):\n",
    "        t = np.zeros(shape=(n_class, 1))\n",
    "        t[x] = 1\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training custom gbdt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [15:37<00:00, 468.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish training... time cost: 937.0571110248566s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "custom_gbdt = GBDT(n_estimators=2, learning_rate=0.001)\n",
    "print('start training custom gbdt...')\n",
    "start = time.time()\n",
    "custom_gbdt.fit(X[:100], y[:100])\n",
    "end = time.time()\n",
    "print('finish training... time cost: {}s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_custom = custom_gbdt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom gbdt test acc: 0.3637\n"
     ]
    }
   ],
   "source": [
    "print('custom gbdt test acc: {}'.format((sum(predict_custom == np.array(y_test)))/len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
